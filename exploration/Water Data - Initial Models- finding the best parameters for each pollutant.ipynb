{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import classification_report, classification \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#read in the data and format some columns\n",
    "data = pd.read_csv('warning_level_data.csv', header = 0)\n",
    "data['StartDate'] = pd.to_datetime(data.StartDate)\n",
    "data.WarningCode = data.WarningCode.astype(int)\n",
    "#convert date to a time delta from today in days\n",
    "data['TimeDelta']=(data.StartDate.apply(lambda x: (dt.datetime.today()-x).days))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LocationIdentifier</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>StartDate</th>\n",
       "      <th>Pollutant</th>\n",
       "      <th>WarningCode</th>\n",
       "      <th>WarningLevel</th>\n",
       "      <th>TimeDelta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11NPSWRD_WQX-PORE_319_EU-L</td>\n",
       "      <td>37.970285</td>\n",
       "      <td>-122.727744</td>\n",
       "      <td>2012-01-23</td>\n",
       "      <td>Nitrate</td>\n",
       "      <td>0</td>\n",
       "      <td>Green</td>\n",
       "      <td>1765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11NPSWRD_WQX-PORE_319_EU-L</td>\n",
       "      <td>37.970285</td>\n",
       "      <td>-122.727744</td>\n",
       "      <td>2012-03-13</td>\n",
       "      <td>Nitrate</td>\n",
       "      <td>0</td>\n",
       "      <td>Green</td>\n",
       "      <td>1715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11NPSWRD_WQX-PORE_319_EU-L</td>\n",
       "      <td>37.970285</td>\n",
       "      <td>-122.727744</td>\n",
       "      <td>2012-11-28</td>\n",
       "      <td>Nitrate</td>\n",
       "      <td>0</td>\n",
       "      <td>Green</td>\n",
       "      <td>1455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11NPSWRD_WQX-PORE_319_EU-L</td>\n",
       "      <td>37.970285</td>\n",
       "      <td>-122.727744</td>\n",
       "      <td>2014-02-09</td>\n",
       "      <td>Nitrate</td>\n",
       "      <td>0</td>\n",
       "      <td>Green</td>\n",
       "      <td>1017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11NPSWRD_WQX-PORE_319_EU-L</td>\n",
       "      <td>37.970285</td>\n",
       "      <td>-122.727744</td>\n",
       "      <td>2014-02-11</td>\n",
       "      <td>Nitrate</td>\n",
       "      <td>0</td>\n",
       "      <td>Green</td>\n",
       "      <td>1015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           LocationIdentifier   Latitude   Longitude  StartDate Pollutant  \\\n",
       "0  11NPSWRD_WQX-PORE_319_EU-L  37.970285 -122.727744 2012-01-23   Nitrate   \n",
       "1  11NPSWRD_WQX-PORE_319_EU-L  37.970285 -122.727744 2012-03-13   Nitrate   \n",
       "2  11NPSWRD_WQX-PORE_319_EU-L  37.970285 -122.727744 2012-11-28   Nitrate   \n",
       "3  11NPSWRD_WQX-PORE_319_EU-L  37.970285 -122.727744 2014-02-09   Nitrate   \n",
       "4  11NPSWRD_WQX-PORE_319_EU-L  37.970285 -122.727744 2014-02-11   Nitrate   \n",
       "\n",
       "   WarningCode WarningLevel  TimeDelta  \n",
       "0            0        Green       1765  \n",
       "1            0        Green       1715  \n",
       "2            0        Green       1455  \n",
       "3            0        Green       1017  \n",
       "4            0        Green       1015  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Nitrate', 'Chromium', 'Arsenic', 'Lead', 'Copper', 'Fluoride',\n",
       "       'Selenium', 'Cadmium', 'Beryllium', 'Mercury', 'Nitrite', 'Barium',\n",
       "       'Antimony', 'TTHMs', 'Xylene', 'HAA5', 'PCBs', 'Simazine'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pol = data.Pollutant.unique()\n",
    "pol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#break into training and test\n",
    "\n",
    "def splitData(df):\n",
    "    #check how many unique sites we are measureing this pollutant at\n",
    "    numLocations = df.LocationIdentifier.unique().size\n",
    "    \n",
    "    #pull out randomly selected entire location ids for the test set\n",
    "    trainLocations = np.random.choice(df.LocationIdentifier.unique(), int(.8*numLocations), replace = False)\n",
    "    testLocations = np.setdiff1d(df.LocationIdentifier.unique(), trainLocations)\n",
    "\n",
    "    #subset the data using the train and test location identifiers\n",
    "    train_data = df[df.LocationIdentifier.isin(trainLocations)]\n",
    "    test_data = df[df.LocationIdentifier.isin(testLocations)]\n",
    "\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plots using the confusion matrix to plot precision and recall\n",
    "#in order to make this useful need to increase the number of K values tried in the runKNNModel function\n",
    "\n",
    "def PRplots(cm_dict):\n",
    "    fig, axes = plt.subplots(1,3, sharey=True, figsize=(14,4))\n",
    "    for k in cm_dict:\n",
    "        cm = cm_dict[k]\n",
    "        support = cm.sum(axis=1)\n",
    "        accuracy = cm.diagonal().sum() / cm.sum().astype(float)\n",
    "        recall = (cm.diagonal() / support.astype(float))\n",
    "        precision = (cm.diagonal()  / cm.sum(axis=0).astype(float))\n",
    "        f1 = 2*precision*recall / (precision+recall)\n",
    "        for ax, r, p in zip(axes, recall, precision):\n",
    "            ax.plot(k,r, marker='$R$', c=(1,0,0), markeredgecolor='none', label='recall')\n",
    "            ax.plot(k,p, marker='$P$', c=(0,0,1), markeredgecolor='none', label='precision')\n",
    "    [ax.set_title('Warning Code: {}'.format(i), size=16) for i,ax in enumerate(axes)];\n",
    "    [ax.set_xlabel('k', size=14) for ax in axes];\n",
    "    fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf OK\n",
      "clf fit OK\n",
      "Best hyperparameters: \n",
      "('For pollutant ', 'Nitrate', ' we don`t have enough data to try different parameters.')\n",
      "clf OK\n",
      "clf fit OK\n",
      "Best hyperparameters: \n",
      "('For pollutant ', 'Chromium', ' we don`t have enough data to try different parameters.')\n",
      "clf OK\n",
      "clf fit OK\n",
      "Best hyperparameters: \n",
      "('For pollutant ', 'Arsenic', ' we don`t have enough data to try different parameters.')\n",
      "clf OK\n",
      "clf fit OK\n",
      "Best hyperparameters: \n",
      "('For pollutant ', 'Lead', ' we don`t have enough data to try different parameters.')\n",
      "clf OK\n",
      "clf fit OK\n",
      "Best hyperparameters: \n",
      "('For pollutant ', 'Copper', ' we don`t have enough data to try different parameters.')\n",
      "clf OK\n",
      "clf fit OK\n",
      "Best hyperparameters: \n",
      "('For pollutant ', 'Fluoride', ' we don`t have enough data to try different parameters.')\n",
      "clf OK\n",
      "clf fit OK\n",
      "Best hyperparameters: \n",
      "('For pollutant ', 'Selenium', ' we don`t have enough data to try different parameters.')\n",
      "clf OK\n",
      "clf fit OK\n",
      "Best hyperparameters: \n",
      "('For pollutant ', 'Cadmium', ' we don`t have enough data to try different parameters.')\n",
      "clf OK\n",
      "clf fit OK\n",
      "Best hyperparameters: \n",
      "('For pollutant ', 'Beryllium', ' we don`t have enough data to try different parameters.')\n",
      "clf OK\n",
      "clf fit OK\n",
      "Best hyperparameters: \n",
      "('For pollutant ', 'Mercury', ' we don`t have enough data to try different parameters.')\n",
      "clf OK\n",
      "clf fit OK\n",
      "Best hyperparameters: \n",
      "('For pollutant ', 'Nitrite', ' we don`t have enough data to try different parameters.')\n",
      "clf OK\n",
      "clf fit OK\n",
      "Best hyperparameters: \n",
      "('For pollutant ', 'Barium', ' we don`t have enough data to try different parameters.')\n",
      "clf OK\n",
      "clf fit OK\n",
      "Best hyperparameters: \n",
      "('For pollutant ', 'Antimony', ' we don`t have enough data to try different parameters.')\n",
      "clf OK\n",
      "clf fit OK\n",
      "Best hyperparameters: \n",
      "('For pollutant ', 'TTHMs', ' we don`t have enough data to try different parameters.')\n",
      "clf OK\n",
      "clf fit OK\n",
      "Best hyperparameters: \n",
      "('For pollutant ', 'Xylene', ' we don`t have enough data to try different parameters.')\n",
      "clf OK\n",
      "clf fit OK\n",
      "Best hyperparameters: \n",
      "('For pollutant ', 'HAA5', ' we don`t have enough data to try different parameters.')\n",
      "clf OK\n",
      "clf fit OK\n",
      "Best hyperparameters: \n",
      "('For pollutant ', 'PCBs', ' we don`t have enough data to try different parameters.')\n",
      "clf OK\n",
      "clf fit OK\n",
      "Best hyperparameters: \n",
      "('For pollutant ', 'Simazine', ' we don`t have enough data to try different parameters.')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# using Ashley's function, split the data into testing and training\n",
    "train_data, test_data = splitData(df)\n",
    "train_labels = train_data.WarningCode\n",
    "\n",
    "# find the best parameters in RF and kNN\n",
    "def best_params(model, parameters, train_data, train_labels):\n",
    "    RF = RandomForestClassifier()\n",
    "    kNN = KNeighborsClassifier()\n",
    "    parameters_RF = [{\"n_estimators\": [4, 5, 6]}]\n",
    "    parameters_kNN = [{\"n_neighbors\": [2, 3, 4, 5, 6, 7, 8]}]\n",
    "    for i in range(len(pol)):\n",
    "        df = data[data.Pollutant == pol[i]]\n",
    "        train_data, test_data = splitData(df)\n",
    "        train_labels = train_data.WarningCode\n",
    "        try:\n",
    "            clf_rf = GridSearchCV(RF, parameters_RF, scoring=\"accuracy\")\n",
    "            clf_knn = GridSearchCV(kNN, parameters_kNN, scoring=\"accuracy\")\n",
    "            print 'clf OK'\n",
    "            clf_rf.fit(X=train_data[['Latitude', 'Longitude', 'TimeDelta']], y=train_data.WarningCode)\n",
    "            clf_knn.fit(X=train_data[['Latitude', 'Longitude', 'TimeDelta']], y=train_data.WarningCode)\n",
    "            print 'clf fit OK'\n",
    "            best_estimator_rf = clf_rf.best_estimator_\n",
    "            best_estimator_knn = clf_knn.best_estimator_\n",
    "            #print 'best_estimator OK'\n",
    "            print ('Best hyperparameters: ')\n",
    "            log_info('RF: ' + str(clf_rf.best_params_))\n",
    "            log_info('kNN: ' + str(clf_knn.best_params_))\n",
    "            log_info('Best hyperparameters: ' + str(clf.best_params_))\n",
    "            pass\n",
    "        except:\n",
    "            print ('For pollutant ', pol[i], ' we don`t have enough data to try different parameters.')\n",
    "            pass\n",
    "    return\n",
    "\n",
    "best_params(model, parameters, train_data, train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
